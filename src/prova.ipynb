{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/train.csv\", low_memory=False)\n",
    "df[\"Num_of_Loan\"] = df[\"Num_of_Loan\"].str.replace(\"_\", \"\")\n",
    "df[\"Num_of_Loan\"] = pd.to_numeric(df[\"Num_of_Loan\"])\n",
    "\n",
    "df[\"Num_of_Delayed_Payment\"] = df[\"Num_of_Delayed_Payment\"].str.replace(\"_\", \"\")\n",
    "df[\"Num_of_Delayed_Payment\"] = pd.to_numeric(df[\"Num_of_Delayed_Payment\"])\n",
    "\n",
    "mask = df.Num_of_Delayed_Payment.notna()\n",
    "features = [\"Num_of_Loan\", \"Num_of_Delayed_Payment\", \"Interest_Rate\"]\n",
    "X = df.loc[mask, features].to_numpy()\n",
    "\n",
    "y = df.loc[mask, \"Credit_Score\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>Interest_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>92998.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.009960</td>\n",
       "      <td>30.923342</td>\n",
       "      <td>72.466040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.647879</td>\n",
       "      <td>226.031892</td>\n",
       "      <td>466.422621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1496.000000</td>\n",
       "      <td>4397.000000</td>\n",
       "      <td>5797.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Num_of_Loan  Num_of_Delayed_Payment  Interest_Rate\n",
       "count  100000.000000            92998.000000  100000.000000\n",
       "mean        3.009960               30.923342      72.466040\n",
       "std        62.647879              226.031892     466.422621\n",
       "min      -100.000000               -3.000000       1.000000\n",
       "25%         1.000000                9.000000       8.000000\n",
       "50%         3.000000               14.000000      13.000000\n",
       "75%         5.000000               18.000000      20.000000\n",
       "max      1496.000000             4397.000000    5797.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "y_norm = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.any(X>0, axis=1)\n",
    "X = X[mask]\n",
    "y_norm = y_norm[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_norm, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X.shape[-1]\n",
    "n_output = np.unique(y_norm).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arch = [\n",
    "    Dense(units=n_input, activation='relu'),\n",
    "    Dense(units=n_output, activation='linear')\n",
    "]\n",
    "\n",
    "model = Sequential(Arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1860/1860 [==============================] - 2s 913us/step - loss: 2.1402 - val_loss: 1.3968\n",
      "Epoch 2/100\n",
      "1860/1860 [==============================] - 2s 857us/step - loss: 0.9798 - val_loss: 0.8927\n",
      "Epoch 3/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8825 - val_loss: 0.8708\n",
      "Epoch 4/100\n",
      "1860/1860 [==============================] - 2s 850us/step - loss: 0.8798 - val_loss: 0.8758\n",
      "Epoch 5/100\n",
      "1860/1860 [==============================] - 2s 846us/step - loss: 0.8841 - val_loss: 0.8727\n",
      "Epoch 6/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8780 - val_loss: 0.8926\n",
      "Epoch 7/100\n",
      "1860/1860 [==============================] - 2s 894us/step - loss: 0.8699 - val_loss: 0.8482\n",
      "Epoch 8/100\n",
      "1860/1860 [==============================] - 2s 854us/step - loss: 0.8684 - val_loss: 0.8674\n",
      "Epoch 9/100\n",
      "1860/1860 [==============================] - 2s 867us/step - loss: 0.8707 - val_loss: 0.9327\n",
      "Epoch 10/100\n",
      "1860/1860 [==============================] - 2s 866us/step - loss: 0.8672 - val_loss: 0.8508\n",
      "Epoch 11/100\n",
      "1860/1860 [==============================] - 2s 887us/step - loss: 0.8674 - val_loss: 0.8518\n",
      "Epoch 12/100\n",
      "1860/1860 [==============================] - 2s 900us/step - loss: 0.8676 - val_loss: 0.8689\n",
      "Epoch 13/100\n",
      "1860/1860 [==============================] - 2s 892us/step - loss: 0.8641 - val_loss: 0.8492\n",
      "Epoch 14/100\n",
      "1860/1860 [==============================] - 2s 874us/step - loss: 0.8646 - val_loss: 0.8718\n",
      "Epoch 15/100\n",
      "1860/1860 [==============================] - 2s 904us/step - loss: 0.8648 - val_loss: 0.8668\n",
      "Epoch 16/100\n",
      "1860/1860 [==============================] - 2s 917us/step - loss: 0.8671 - val_loss: 0.8525\n",
      "Epoch 17/100\n",
      "1860/1860 [==============================] - 2s 856us/step - loss: 0.8649 - val_loss: 0.8574\n",
      "Epoch 18/100\n",
      "1860/1860 [==============================] - 2s 837us/step - loss: 0.8654 - val_loss: 0.8509\n",
      "Epoch 19/100\n",
      "1860/1860 [==============================] - 2s 880us/step - loss: 0.8642 - val_loss: 0.8626\n",
      "Epoch 20/100\n",
      "1860/1860 [==============================] - 2s 858us/step - loss: 0.8661 - val_loss: 0.8941\n",
      "Epoch 21/100\n",
      "1860/1860 [==============================] - 2s 849us/step - loss: 0.8664 - val_loss: 0.8728\n",
      "Epoch 22/100\n",
      "1860/1860 [==============================] - 2s 840us/step - loss: 0.8639 - val_loss: 0.8610\n",
      "Epoch 23/100\n",
      "1860/1860 [==============================] - 2s 851us/step - loss: 0.8659 - val_loss: 0.8597\n",
      "Epoch 24/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8637 - val_loss: 0.8508\n",
      "Epoch 25/100\n",
      "1860/1860 [==============================] - 2s 849us/step - loss: 0.8652 - val_loss: 0.8722\n",
      "Epoch 26/100\n",
      "1860/1860 [==============================] - 2s 848us/step - loss: 0.8650 - val_loss: 0.8457\n",
      "Epoch 27/100\n",
      "1860/1860 [==============================] - 2s 851us/step - loss: 0.8658 - val_loss: 0.8554\n",
      "Epoch 28/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8651 - val_loss: 0.8508\n",
      "Epoch 29/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8647 - val_loss: 0.8728\n",
      "Epoch 30/100\n",
      "1860/1860 [==============================] - 2s 844us/step - loss: 0.8647 - val_loss: 0.8525\n",
      "Epoch 31/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8632 - val_loss: 0.8460\n",
      "Epoch 32/100\n",
      "1860/1860 [==============================] - 2s 853us/step - loss: 0.8639 - val_loss: 0.8562\n",
      "Epoch 33/100\n",
      "1860/1860 [==============================] - 2s 849us/step - loss: 0.8645 - val_loss: 0.8494\n",
      "Epoch 34/100\n",
      "1860/1860 [==============================] - 2s 870us/step - loss: 0.8654 - val_loss: 0.8452\n",
      "Epoch 35/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8636 - val_loss: 0.8472\n",
      "Epoch 36/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8627 - val_loss: 0.8457\n",
      "Epoch 37/100\n",
      "1860/1860 [==============================] - 2s 848us/step - loss: 0.8650 - val_loss: 0.8570\n",
      "Epoch 38/100\n",
      "1860/1860 [==============================] - 2s 851us/step - loss: 0.8635 - val_loss: 0.8540\n",
      "Epoch 39/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8645 - val_loss: 0.8502\n",
      "Epoch 40/100\n",
      "1860/1860 [==============================] - 2s 850us/step - loss: 0.8633 - val_loss: 0.8611\n",
      "Epoch 41/100\n",
      "1860/1860 [==============================] - 2s 856us/step - loss: 0.8636 - val_loss: 0.8518\n",
      "Epoch 42/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8668 - val_loss: 0.8535\n",
      "Epoch 43/100\n",
      "1860/1860 [==============================] - 2s 837us/step - loss: 0.8629 - val_loss: 0.8486\n",
      "Epoch 44/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8645 - val_loss: 0.8599\n",
      "Epoch 45/100\n",
      "1860/1860 [==============================] - 2s 840us/step - loss: 0.8636 - val_loss: 0.8495\n",
      "Epoch 46/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8658 - val_loss: 0.8603\n",
      "Epoch 47/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8620 - val_loss: 0.8599\n",
      "Epoch 48/100\n",
      "1860/1860 [==============================] - 2s 853us/step - loss: 0.8654 - val_loss: 0.8589\n",
      "Epoch 49/100\n",
      "1860/1860 [==============================] - 2s 841us/step - loss: 0.8622 - val_loss: 0.8542\n",
      "Epoch 50/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8656 - val_loss: 0.8520\n",
      "Epoch 51/100\n",
      "1860/1860 [==============================] - 2s 839us/step - loss: 0.8641 - val_loss: 0.8607\n",
      "Epoch 52/100\n",
      "1860/1860 [==============================] - 2s 852us/step - loss: 0.8636 - val_loss: 0.8577\n",
      "Epoch 53/100\n",
      "1860/1860 [==============================] - 2s 843us/step - loss: 0.8629 - val_loss: 0.8498\n",
      "Epoch 54/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8631 - val_loss: 0.8665\n",
      "Epoch 55/100\n",
      "1860/1860 [==============================] - 2s 856us/step - loss: 0.8638 - val_loss: 0.8591\n",
      "Epoch 56/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8634 - val_loss: 0.8581\n",
      "Epoch 57/100\n",
      "1860/1860 [==============================] - 2s 840us/step - loss: 0.8643 - val_loss: 0.8539\n",
      "Epoch 58/100\n",
      "1860/1860 [==============================] - 2s 849us/step - loss: 0.8642 - val_loss: 0.8542\n",
      "Epoch 59/100\n",
      "1860/1860 [==============================] - 2s 844us/step - loss: 0.8646 - val_loss: 0.8577\n",
      "Epoch 60/100\n",
      "1860/1860 [==============================] - 2s 841us/step - loss: 0.8619 - val_loss: 0.8683\n",
      "Epoch 61/100\n",
      "1860/1860 [==============================] - 2s 846us/step - loss: 0.8627 - val_loss: 0.8821\n",
      "Epoch 62/100\n",
      "1860/1860 [==============================] - 2s 857us/step - loss: 0.8648 - val_loss: 0.8521\n",
      "Epoch 63/100\n",
      "1860/1860 [==============================] - 2s 848us/step - loss: 0.8620 - val_loss: 0.8740\n",
      "Epoch 64/100\n",
      "1860/1860 [==============================] - 2s 846us/step - loss: 0.8622 - val_loss: 0.8560\n",
      "Epoch 65/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8655 - val_loss: 0.8468\n",
      "Epoch 66/100\n",
      "1860/1860 [==============================] - 2s 839us/step - loss: 0.8624 - val_loss: 0.8507\n",
      "Epoch 67/100\n",
      "1860/1860 [==============================] - 2s 844us/step - loss: 0.8645 - val_loss: 0.8832\n",
      "Epoch 68/100\n",
      "1860/1860 [==============================] - 2s 834us/step - loss: 0.8625 - val_loss: 0.8519\n",
      "Epoch 69/100\n",
      "1860/1860 [==============================] - 2s 862us/step - loss: 0.8641 - val_loss: 0.8604\n",
      "Epoch 70/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8639 - val_loss: 0.8554\n",
      "Epoch 71/100\n",
      "1860/1860 [==============================] - 2s 840us/step - loss: 0.8643 - val_loss: 0.8490\n",
      "Epoch 72/100\n",
      "1860/1860 [==============================] - 2s 858us/step - loss: 0.8639 - val_loss: 0.8549\n",
      "Epoch 73/100\n",
      "1860/1860 [==============================] - 2s 843us/step - loss: 0.8641 - val_loss: 0.8560\n",
      "Epoch 74/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8631 - val_loss: 0.8502\n",
      "Epoch 75/100\n",
      "1860/1860 [==============================] - 2s 840us/step - loss: 0.8640 - val_loss: 0.8609\n",
      "Epoch 76/100\n",
      "1860/1860 [==============================] - 2s 863us/step - loss: 0.8662 - val_loss: 0.8607\n",
      "Epoch 77/100\n",
      "1860/1860 [==============================] - 2s 852us/step - loss: 0.8626 - val_loss: 0.8659\n",
      "Epoch 78/100\n",
      "1860/1860 [==============================] - 2s 849us/step - loss: 0.8651 - val_loss: 0.8513\n",
      "Epoch 79/100\n",
      "1860/1860 [==============================] - 2s 846us/step - loss: 0.8629 - val_loss: 0.8481\n",
      "Epoch 80/100\n",
      "1860/1860 [==============================] - 2s 854us/step - loss: 0.8653 - val_loss: 0.8506\n",
      "Epoch 81/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8653 - val_loss: 0.8680\n",
      "Epoch 82/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8637 - val_loss: 0.8487\n",
      "Epoch 83/100\n",
      "1860/1860 [==============================] - 2s 854us/step - loss: 0.8646 - val_loss: 0.8490\n",
      "Epoch 84/100\n",
      "1860/1860 [==============================] - 2s 848us/step - loss: 0.8603 - val_loss: 0.8761\n",
      "Epoch 85/100\n",
      "1860/1860 [==============================] - 2s 841us/step - loss: 0.8632 - val_loss: 0.8469\n",
      "Epoch 86/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8658 - val_loss: 0.8581\n",
      "Epoch 87/100\n",
      "1860/1860 [==============================] - 2s 847us/step - loss: 0.8643 - val_loss: 0.8597\n",
      "Epoch 88/100\n",
      "1860/1860 [==============================] - 2s 841us/step - loss: 0.8643 - val_loss: 0.8569\n",
      "Epoch 89/100\n",
      "1860/1860 [==============================] - 2s 841us/step - loss: 0.8632 - val_loss: 0.8606\n",
      "Epoch 90/100\n",
      "1860/1860 [==============================] - 2s 871us/step - loss: 0.8648 - val_loss: 0.8804\n",
      "Epoch 91/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8622 - val_loss: 0.8482\n",
      "Epoch 92/100\n",
      "1860/1860 [==============================] - 2s 839us/step - loss: 0.8639 - val_loss: 0.8613\n",
      "Epoch 93/100\n",
      "1860/1860 [==============================] - 2s 830us/step - loss: 0.8634 - val_loss: 0.8472\n",
      "Epoch 94/100\n",
      "1860/1860 [==============================] - 2s 845us/step - loss: 0.8683 - val_loss: 0.8548\n",
      "Epoch 95/100\n",
      "1860/1860 [==============================] - 2s 846us/step - loss: 0.8642 - val_loss: 0.8548\n",
      "Epoch 96/100\n",
      "1860/1860 [==============================] - 2s 853us/step - loss: 0.8644 - val_loss: 0.8541\n",
      "Epoch 97/100\n",
      "1860/1860 [==============================] - 2s 842us/step - loss: 0.8628 - val_loss: 0.8534\n",
      "Epoch 98/100\n",
      "1860/1860 [==============================] - 2s 864us/step - loss: 0.8650 - val_loss: 0.8531\n",
      "Epoch 99/100\n",
      "1860/1860 [==============================] - 2s 839us/step - loss: 0.8643 - val_loss: 0.8552\n",
      "Epoch 100/100\n",
      "1860/1860 [==============================] - 2s 840us/step - loss: 0.8647 - val_loss: 0.8562\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(X_train)\n",
    "f_X = tensorflow.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.argmax(f_X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([ 9573, 18575, 46250], dtype=int64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(f_X, axis=1), return_counts=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.33      0.39     13332\n",
      "           1       0.59      0.51      0.55     21616\n",
      "           2       0.62      0.73      0.67     39450\n",
      "\n",
      "    accuracy                           0.59     74398\n",
      "   macro avg       0.56      0.52      0.53     74398\n",
      "weighted avg       0.58      0.59      0.58     74398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f4513b2a90>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "#plt.xlim(0,20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bec9a4fae84d278cecf29348292e5365ba4299e5d55caa00177d12a99bb9320"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
